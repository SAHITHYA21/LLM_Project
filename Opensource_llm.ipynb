{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d8ff996-da6b-4863-a658-950bb77cd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "model = \"EleutherAI/gpt-neo-125m\" #LLM from Internet, text generation model\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb760967-5fd2-45ff-a9f1-03229e3d0119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32e4ed5d-d195-4cb2-b314-922cda7ad786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a story about alien life?\" \"It might be fun.\" \"But the answer is no.\" \"The answer is you.\" \"I'm not a monster.\" \"I'm a real human.\" \"But I'm not that kind of a person.\" \"What do you know about me?\" \"No.\" \"No.\" \"I'm not a human.\" \"You're a robot.\" \"You're like the one in your dream.\" \"You're my friend.\" \"I'm a human.\" \"A robot.\" \"I love you.\" \"I love you.\" \"I love you.\" \"I love you.\" \"Do you love me?\" \"What are you talking about?\" \"That you are a robot?\" \"You're a robot.\" \"A robot.\" \"I love you.\" \"You're like this?\" \"Yes!\" \"You're like a robot.\" \"You're like this?\" \"Yes!\" \"You're like this?\" \"Yes!\" \"You're like a robot\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline, PromptTemplate,LLMChain\n",
    "# Loading the LLM from internet and wraping it with HuggungFacePipeline and use that object\n",
    "llm = HuggingFacePipeline(pipeline=pipeline) \n",
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"content\"],\n",
    "    template = \"Tell me a story about {content}\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt\n",
    ")\n",
    "print(chain.run(\"alien\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "798fc68d-2e5d-4e74-a77b-7dac48708b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a story about Life\n",
      "\n",
      "Life is a wonderful story. It is a wonderful story about a wonderful life. I have a little story about life and it is about my life. When I was in my early forties I had my first baby, but I did not have the time to tell my parents about it at that time, so it was a long way to go, but when my mother told me the story of my life it was a great one! I love all the things I do, and I have been so excited about the story of life, and the way I have been and the stories that are being told. I have been a happy, healthy, healthy kid, and I have been so lucky to have been blessed with my first husband.\n",
      "\n",
      "I am in the process of writing a story about my life. I have been reading a story by Dr. Martin Luther King, and I am excited about what I can come up with for this story.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"Life\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e90f3a-eaa4-44bd-a72f-c1256d07cf62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
